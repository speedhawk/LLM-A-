{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPVLhHSB4MTng3CQvFVL68e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/speedhawk/LLM-A-/blob/main/PPO_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm_db0Pe6JX8",
        "outputId": "8823eb3b-d58f-4aff-cd40-fdca1dd3abe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "mHQ9qaOQ6OPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import copy\n",
        "import re\n",
        "import openpyxl\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cW8ZwjVq6P_J",
        "outputId": "60f6c3bf-acbb-4843-baa8-551285112260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L228qFjD6VKV",
        "outputId": "e236facd-f41c-4f7d-92b8-8f53ea102816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler, SequentialSampler\n",
        "from torch.distributions import Categorical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "45VEp7Sr6Vqk",
        "outputId": "eb6ed478-b5cc-4e38-a9d2-b4816bc495ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "from collections import namedtuple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-rs01Zf-6W9T",
        "outputId": "984ca23f-7887-42a1-b3ee-88e7236fd7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Transition = namedtuple('Transition', ['state', 'action', 'pre_prob', 'reward', 'next_state'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "n4R_u7B16Ylz",
        "outputId": "e146a933-cd6b-4607-f6db-7b8ed4351597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AC_PPO_ini Model\n",
        "class Critic(nn.Module):\n",
        "  def __init__(self, input):\n",
        "      super(Critic, self).__init__()\n",
        "      self.dim = 128\n",
        "      self.fc1 = nn.Linear(input, self.dim)\n",
        "      self.fc2 = nn.Linear(self.dim, self.dim)\n",
        "      self.state_value = nn.Linear(self.dim, 1)\n",
        "\n",
        "      # layer normalization\n",
        "      self.bn1 = nn.LayerNorm(self.dim)\n",
        "      self.bn2 = nn.LayerNorm(self.dim)\n",
        "\n",
        "      self.initialization()\n",
        "\n",
        "  def initialization(self):   # weight initialization\n",
        "    nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('tanh'))\n",
        "    nn.init.xavier_uniform_(self.fc2.weight, gain=nn.init.calculate_gain('tanh'))\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = F.tanh(self.fc1(x))\n",
        "      x = self.bn1(x)\n",
        "      x = F.tanh(self.fc2(x))\n",
        "      x = self.bn2(x)\n",
        "      value = self.state_value(x)\n",
        "      return value\n",
        "\n",
        "class Actor(nn.Module):\n",
        "  \"\"\"\n",
        "  INPUT: the position as the state of agent\n",
        "  OUPPUT: 8-dim Teansor, the probability of each actions\n",
        "  \"\"\"\n",
        "  def __init__(self, input, output):\n",
        "      super(Actor, self).__init__()\n",
        "      self.dim = 128\n",
        "      self.fc1 = nn.Linear(input, self.dim)\n",
        "      self.fc2 = nn.Linear(self.dim, self.dim)\n",
        "      self.action_head = nn.Linear(self.dim, output)\n",
        "\n",
        "      # layer normalization\n",
        "      self.bn1 = nn.LayerNorm(self.dim)\n",
        "      self.bn2 = nn.LayerNorm(self.dim)\n",
        "\n",
        "      # # noise generator\n",
        "      # self.mu = 0.0\n",
        "      # self.stdv = 0.1\n",
        "\n",
        "\n",
        "      self.initialization()\n",
        "\n",
        "  def initialization(self):\n",
        "    nn.init.xavier_uniform_(self.fc1.weight, gain=nn.init.calculate_gain('tanh'))\n",
        "    nn.init.xavier_uniform_(self.fc2.weight, gain=nn.init.calculate_gain('tanh'))\n",
        "\n",
        "  def noise_generate(self, actions):\n",
        "    noise = torch.normal(mean=self.mu, std=self.stdv, size=actions.size())\n",
        "    return noise\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = F.tanh(self.fc1(x))\n",
        "      x = self.bn1(x)\n",
        "      x = F.tanh(self.fc2(x))\n",
        "      x = self.bn2(x)\n",
        "      x = self.action_head(x)\n",
        "      # x = x + self.noise_generate(x).to('cpu')\n",
        "      action_prob = F.softmax(x, dim=1)\n",
        "      return action_prob"
      ],
      "metadata": {
        "id": "fS4zHXbQ6aOY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "eab8cb4b-7b31-4d3c-8b4b-83a4cb5eab2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PPO agent\n",
        "class PPO():\n",
        "  def __init__(self, path, start, goal, map_range, border, map_sheet='Sheet1', reward_sheet='Sheet2') -> None:\n",
        "\n",
        "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # environment\n",
        "    self.start_node = np.array(start)\n",
        "    self.target_node = np.array(goal)\n",
        "    self.cur_node = self.start_node\n",
        "    self.pre_node = self.start_node\n",
        "\n",
        "    self.file_path = path\n",
        "    self.map_range = map_range\n",
        "    self.map_sheet = map_sheet\n",
        "    self.reward_sheet = reward_sheet\n",
        "    self.map = None\n",
        "    self.reward_distribution = None\n",
        "\n",
        "    # map scope\n",
        "    self.max_border = border\n",
        "    self.x_max = None\n",
        "    self.x_min = None\n",
        "    self.y_max = None\n",
        "    self.y_min = None\n",
        "\n",
        "    self.action_space = {0: [1, 0],\n",
        "                           1: [-1, 0],\n",
        "                           2: [0, 1],\n",
        "                           3: [0, -1],\n",
        "                           4: [-1, 1],\n",
        "                           5: [1, 1],\n",
        "                           6: [-1, -1],\n",
        "                           7: [1, -1]}\n",
        "\n",
        "    # learning param:\n",
        "\n",
        "    self.memory = {}  # this list consists of transations for the number of n times of batch_size.\n",
        "    self.memory_len = 50\n",
        "    self.batch_size = 128\n",
        "    self.actor_max_grad = 0.05\n",
        "    # self.critic_max_grad = 1.5\n",
        "    self.actor = Actor(2 * border + 8, 8).to(self.device)\n",
        "    self.critic = Critic(2 * border + 8).to(self.device)\n",
        "    self.gamma = 0.99\n",
        "    self.lamda = 0.95\n",
        "    self.a_lr = 2e-4\n",
        "    self.c_lr = 5e-3\n",
        "    self.clip = 0.3\n",
        "    self.entropy_coe = 0.01\n",
        "    # self.l1_co = 0.001\n",
        "    # self.l2_co = 0.005\n",
        "\n",
        "    self.actor_opt = optim.Adam(self.actor.parameters(), lr=self.a_lr)\n",
        "    self.critic_opt = optim.Adam(self.critic.parameters(), lr=self.c_lr)\n",
        "\n",
        "    # iteration param:\n",
        "\n",
        "    self.pre_reward_sign = float(0)\n",
        "    self.sign_record = 0\n",
        "    self.pre_unreshaped_reward = 0.0\n",
        "\n",
        "    self.step_thr = 200\n",
        "    self.steps = 0\n",
        "\n",
        "    # statistic param:\n",
        "    self.avg = []\n",
        "    self.total_avg = []\n",
        "    self.avg_step = []\n",
        "    self.total_step = []\n",
        "\n",
        "\n",
        "  def generate_map(self):\n",
        "    wb = openpyxl.load_workbook(self.file_path)\n",
        "    ws = wb[self.map_sheet]\n",
        "    _range = self.map_range\n",
        "    map = []\n",
        "    for row in ws[_range]:\n",
        "      map_row = []\n",
        "      for cell in row:\n",
        "        map_row.append(cell.value)\n",
        "      map.append(map_row)\n",
        "    map = np.array(map)\n",
        "    self.map = map\n",
        "\n",
        "  def generate_dis_table(self):\n",
        "    wb = openpyxl.load_workbook(self.file_path)\n",
        "    ws = wb[self.reward_sheet]\n",
        "    _range = self.map_range\n",
        "    dis_table = []\n",
        "    for row in ws[_range]:\n",
        "      dis_table_row = []\n",
        "      for cell in row:\n",
        "        dis_table_row.append(cell.value)\n",
        "      dis_table.append(dis_table_row)\n",
        "    dis_table = np.array(dis_table)\n",
        "    self.reward_distribution = dis_table\n",
        "\n",
        "  def save_checkpoints(self):\n",
        "    torch.save(self.actor.state_dict(), '/content/gdrive/MyDrive/PPO_demo_v4/checkpoints/checkpoints_actor.pt')\n",
        "    torch.save(self.critic.state_dict(), '/content/gdrive/MyDrive/PPO_demo_v4/checkpoints/checkpoints_critic.pt')\n",
        "\n",
        "  def load_checkpoints(self):\n",
        "    self.actor.load_state_dict(torch.load('/content/gdrive/MyDrive/PPO_demo_v4/checkpoints/checkpoints_actor.pt', map_location=torch.device('cpu')))\n",
        "    self.critic.load_state_dict(torch.load('/content/gdrive/MyDrive/PPO_demo_v4/checkpoints/checkpoints_critic.pt', map_location=torch.device('cpu')))\n",
        "\n",
        "    # self.actor.load_state_dict(torch.load('/content/gdrive/MyDrive/PPO_demo_v4/checkpoints/checkpoints_actor.pt'))\n",
        "    # self.critic.load_state_dict(torch.load('/content/gdrive/MyDrive/PPO_demo_v4/checkpoints/checkpoints_critic.pt'))\n",
        "\n",
        "  def save_trans(self, index, trans):\n",
        "    self.memory[index].insert(0, trans)\n",
        "\n",
        "  def vectorized_start(self, episode):\n",
        "\n",
        "\n",
        "    self.x_min = 0\n",
        "    self.x_max = self.max_border - 1\n",
        "    self.y_min = 0\n",
        "    self.y_max = self.max_border - 1\n",
        "\n",
        "    x = random.randint(self.x_min, self.x_max)\n",
        "    y = random.randint(self.y_min, self.y_max)\n",
        "\n",
        "    while self.reward_distribution[x][y] == -1024:\n",
        "      x = random.randint(self.x_min, self.x_max)\n",
        "      y = random.randint(self.y_min, self.y_max)\n",
        "    return np.array([x, y])\n",
        "\n",
        "  def reset(self):\n",
        "    self.cur_node = self.start_node\n",
        "\n",
        "  def get_noise(self, actions):\n",
        "    sigma = 0.1\n",
        "    mu = 0.0\n",
        "    noise_vector = torch.normal(mean=mu, std=sigma, size=actions.size())\n",
        "\n",
        "  def double_hot(self, obs):\n",
        "    double_hot_state = [0] * (self.max_border * 2)\n",
        "    x = obs.tolist()[0]\n",
        "    y = obs.tolist()[1]\n",
        "    double_hot_state[x] = 1\n",
        "    double_hot_state[self.max_border+y] = 1\n",
        "    return double_hot_state\n",
        "\n",
        "  def situation(self, obs):\n",
        "    situation = []\n",
        "    is_obstacle = 0\n",
        "    for i in self.action_space:\n",
        "      sur_obs = (obs + np.array(self.action_space[i])).tolist()\n",
        "      x = sur_obs[0]\n",
        "      y = sur_obs[1]\n",
        "      if x < self.x_min or x > self.x_max or y < self.y_min or y > self.y_min or self.reward_distribution[x][y] == -1024:\n",
        "        is_obstacle = 0\n",
        "      else:\n",
        "        is_obstacle = 1\n",
        "      situation.append(is_obstacle)\n",
        "\n",
        "    return situation\n",
        "\n",
        "  def get_next_obs(self, action):\n",
        "\n",
        "    obs = self.cur_node + np.array(self.action_space[action])\n",
        "    collide_check = 0\n",
        "\n",
        "    obs = obs.tolist()\n",
        "    x = obs[0]\n",
        "    y = obs[1]\n",
        "\n",
        "    if x > self.x_max or x < self.x_min or y > self.y_max or y < self.y_min or self.reward_distribution[x][y] == -1024:\n",
        "      obs = self.cur_node\n",
        "      collide_check = 1\n",
        "\n",
        "    return (np.array(obs), collide_check)\n",
        "\n",
        "  def action_select(self, obs):\n",
        "    possibilities = self.actor(obs).cpu().detach()\n",
        "    # print(f\"p: {possibilities}\")\n",
        "\n",
        "    distrb = Categorical(possibilities)   # attention: Categorical requires a tensor input!\n",
        "    act = distrb.sample().item()\n",
        "\n",
        "    possibilities = possibilities.numpy()\n",
        "    posb = possibilities.item(act)\n",
        "\n",
        "    return act, posb\n",
        "\n",
        "  def get_reward(self, obs):\n",
        "\n",
        "    if obs[1] == 1:\n",
        "      # self.pre_unreshaped_reward = 0.0\n",
        "      return 0.0\n",
        "    else:\n",
        "      obs = obs[0]\n",
        "      x1 = obs[0]\n",
        "      y1 = obs[1]\n",
        "\n",
        "      cur_node = self.cur_node.tolist()\n",
        "      x2 = cur_node[0]\n",
        "      y2 = cur_node[1]\n",
        "\n",
        "      r = float(self.reward_distribution[x1][y1]-self.reward_distribution[x2][y2])\n",
        "\n",
        "      return r\n",
        "\n",
        "  def reward_reshaping(self, reward):\n",
        "    \"\"\"\n",
        "    Except for reshaping the reward, there are two variables to be sustained in this\n",
        "    function:\n",
        "      1. pre_reward_sign: record the last reward sign, used for evaluate sign_record\n",
        "      2. sign_record: record the frequence of nice actions.\n",
        "    \"\"\"\n",
        "\n",
        "    # reward reshaping\n",
        "    r_sign = float(np.sign(reward))\n",
        "    if r_sign == self.pre_reward_sign and r_sign == 1.0:\n",
        "      self.sign_record += 1\n",
        "    else:\n",
        "      self.sign_record = 0\n",
        "\n",
        "    index = 0.1 * (float(self.sign_record))\n",
        "    reward += index\n",
        "    self.pre_reward_sign = r_sign\n",
        "\n",
        "    return reward\n",
        "\n",
        "  def is_done(self, reward):\n",
        "\n",
        "    if reward == -10.0:\n",
        "      return True\n",
        "\n",
        "    return False\n",
        "\n",
        "  def step(self, act):\n",
        "\n",
        "    obs = self.get_next_obs(act)\n",
        "    reward = self.get_reward(obs)\n",
        "    reward = self.reward_reshaping(reward)\n",
        "    done = self.is_done(reward)\n",
        "    inf = 'the current step is ' + str(done)\n",
        "    return obs, reward, done, inf\n",
        "\n",
        "  def critic_train(self):\n",
        "    Transition = namedtuple('Transition', ['state', 'action', 'pre_prob', 'reward', 'next_state', 'G'])\n",
        "\n",
        "    datas = []\n",
        "\n",
        "    for i in range(len(self.memory)):\n",
        "      G = 0.0\n",
        "      for tran in self.memory[i]:\n",
        "        G = tran.reward + self.gamma * G\n",
        "        tran_list = list(tran)\n",
        "        tran = Transition(tran_list[0], tran_list[1], tran_list[2], tran_list[3], tran_list[4], G)\n",
        "        datas.append(tran)\n",
        "\n",
        "    random.shuffle(datas)\n",
        "\n",
        "    states = torch.tensor([trans.state.tolist() for trans in datas], dtype=torch.float).to(self.device)\n",
        "    actions = torch.tensor([trans.action for trans in datas], dtype=torch.long).view(-1, 1).to(self.device)\n",
        "    # actions size: (batch_size, 1)\n",
        "    G = torch.tensor([trans.G for trans in datas], dtype=torch.float).view(-1, 1).to(self.device)\n",
        "    # G size: (batch_size, 1)\n",
        "\n",
        "    for _ in range(2 * len(datas) // self.batch_size):\n",
        "\n",
        "      for index in BatchSampler(SequentialSampler(range(len(datas))), batch_size=self.batch_size, drop_last=False):\n",
        "\n",
        "        v_s = self.critic(states[index]).squeeze(-1)\n",
        "\n",
        "\n",
        "        critic_loss = F.mse_loss(G[index], v_s)\n",
        "\n",
        "        self.critic_opt.zero_grad()\n",
        "        critic_loss.backward()\n",
        "        self.critic_opt.step()\n",
        "\n",
        "  def actor_train(self):\n",
        "\n",
        "    Transition = namedtuple('Transition', ['state', 'action', 'pre_prob', 'reward', 'next_state', 'adv'])\n",
        "\n",
        "    datas = []\n",
        "\n",
        "    for i in range(len(self.memory)):\n",
        "      adv = 0.0\n",
        "      for tran in self.memory[i]:\n",
        "        Q = tran.reward + self.gamma * self.critic(tran.next_state.to(self.device)).detach().item() # Q = r + V(s')\n",
        "        v_s = self.critic(tran.state.to(self.device)).detach().item()\n",
        "        delta = Q - v_s\n",
        "        adv = delta + self.gamma * self.lamda * adv\n",
        "        tran_list = list(tran)\n",
        "        tran = Transition(tran_list[0], tran_list[1], tran_list[2], tran_list[3], tran_list[4], adv)\n",
        "        datas.append(tran)\n",
        "\n",
        "    states = torch.tensor([trans.state.tolist() for trans in datas], dtype=torch.float).to(self.device)\n",
        "    actions = torch.tensor([trans.action for trans in datas], dtype=torch.long).view(-1, 1).to(self.device)\n",
        "    # actions size: (batch_size, 1)\n",
        "    advs = torch.tensor([trans.adv for trans in datas], dtype=torch.float).view(-1, 1).to(self.device)\n",
        "    # advs size: (batch_size, 1)\n",
        "\n",
        "    pre_probs= torch.tensor([trans.pre_prob for trans in datas], dtype=torch.float).view(-1, 1).to(self.device)\n",
        "\n",
        "\n",
        "    for _ in range(2 * len(datas) // self.batch_size):\n",
        "\n",
        "      random.shuffle(datas)\n",
        "\n",
        "      for index in BatchSampler(SequentialSampler(range(len(datas))), batch_size=self.batch_size, drop_last=False):\n",
        "\n",
        "        # Obtain pre_action_probability and cur_action_probability, which is used for calculating ratio and clamped ratio\n",
        "\n",
        "        p = self.actor(states[index].squeeze(1)).squeeze(1).to(device)\n",
        "\n",
        "        cur_probs = p.gather(1, actions[index])\n",
        "        entropies = torch.tensor([Categorical(posb.unsqueeze(0)).entropy().item() for posb in p], dtype=torch.float).view(-1, 1).to(self.device)\n",
        "\n",
        "        ratio = cur_probs / pre_probs[index]\n",
        "        n_advs = (advs[index]-advs[index].mean()) / advs[index].std()\n",
        "        sel_a = ratio * n_advs\n",
        "        sel_b = torch.clamp(ratio, 1-self.clip, 1+self.clip) * n_advs\n",
        "\n",
        "        # Update Actor by minimum ratio mean loss\n",
        "\n",
        "        actor_loss = -torch.min(sel_a, sel_b).mean() - self.entropy_coe * entropies.mean() # entropy regularization loss function\n",
        "        # print(f\"a_loss: {actor_loss}\")\n",
        "        self.actor_opt.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(self.actor.parameters(), self.actor_max_grad)\n",
        "        self.actor_opt.step()\n",
        "\n",
        "# for the purpose of continuity of training, the four functions below is created in case of offline problem so that the data will not be lost after re-connecting.\n",
        "\n",
        "  def load_episodes(self):\n",
        "    file_iter = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/episodes.txt', 'r')\n",
        "    episode = file_iter.read()\n",
        "    file_iter.close()\n",
        "    e = int(episode)\n",
        "    return e\n",
        "\n",
        "  def save_episodes(self):\n",
        "    e = len(self.avg)\n",
        "    file_iter = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/episodes.txt', 'w')\n",
        "    file_iter.write(str(e))\n",
        "    file_iter.close()\n",
        "\n",
        "  def load_records(self):\n",
        "    file_avg_score = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/avg_scores.txt', 'r')\n",
        "    file_avg_step = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/avg_steps.txt', 'r')\n",
        "    file_score = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/scores.txt', 'r')\n",
        "    file_step = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/steps.txt', 'r')\n",
        "    while True:\n",
        "      a_score = file_avg_score.readline()\n",
        "      a_step = file_avg_step.readline()\n",
        "      score = file_score.readline()\n",
        "      step = file_step.readline()\n",
        "      if not a_score:\n",
        "          break\n",
        "      self.avg.append(eval(a_score))\n",
        "      self.avg_step.append(eval(a_step))\n",
        "      self.total_avg.append(eval(score))\n",
        "      self.total_step.append(eval(step))\n",
        "    file_avg_score.close()\n",
        "    file_avg_step.close()\n",
        "    file_score.close()\n",
        "    file_step.close()\n",
        "\n",
        "  def save_records(self):\n",
        "    upper = len(self.avg)\n",
        "    lower = upper - (self.memory_len - 1)\n",
        "    a_scores = self.avg[-self.memory_len:]\n",
        "    a_steps = self.avg_step[-self.memory_len:]\n",
        "    scores = self.total_avg[-self.memory_len:]\n",
        "    steps = self.total_step[-self.memory_len:]\n",
        "    file_avg_score = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/avg_scores.txt', 'a')\n",
        "    file_avg_score.writelines([str(a_sc)+'\\n' for a_sc in a_scores])\n",
        "    file_avg_score.close\n",
        "\n",
        "    file_avg_step = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/avg_steps.txt', 'a')\n",
        "    file_avg_step.writelines([str(a_st)+'\\n' for a_st in a_steps])\n",
        "    file_avg_step.close\n",
        "\n",
        "    file_score = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/scores.txt', 'a')\n",
        "    file_score.writelines([str(sc)+'\\n' for sc in scores])\n",
        "    file_score.close\n",
        "\n",
        "    file_step = open('/content/gdrive/MyDrive/PPO_demo_v4/configuration/steps.txt', 'a')\n",
        "    file_step.writelines([str(st)+'\\n' for st in steps])\n",
        "    file_step.close\n"
      ],
      "metadata": {
        "id": "GItLhoNG6clG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a087a682-68e2-4905-e5b4-66bda0e890a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select an environment**"
      ],
      "metadata": {
        "id": "jXikTtENUlW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Aisle_24'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [1, 22]\n",
        "goal = [21, 2]\n",
        "map_range = 'A1:X24'\n",
        "border = 24\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "jWTfcNNESBur",
        "outputId": "4ba5e554-5473-4415-da3e-4e933a35180d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Canyon_24'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [2, 17]\n",
        "goal = [15, 2]\n",
        "map_range = 'A1:X24'\n",
        "border = 24\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wSYWwnwlSArE",
        "outputId": "68adcfa4-4a35-48dc-e942-db25817b7a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Double_door_24'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [1, 22]\n",
        "goal = [19, 1]\n",
        "map_range = 'A1:X24'\n",
        "border = 24\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lM6B375YSAhg",
        "outputId": "f1ce964e-5cbd-4193-8765-8892a9a8a7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Double_door'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [1, 29]\n",
        "goal = [28, 1]\n",
        "map_range = 'A1:AF32'\n",
        "border = 32\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RhVTP8TMgYrk",
        "outputId": "d7b415f2-7914-4246-94c3-ee945a7a886b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Canyon'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [3, 23]\n",
        "goal = [21, 1]\n",
        "map_range = 'A1:AF32'\n",
        "border = 32\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SvK25e04gYh2",
        "outputId": "84765661-4771-4563-d2f3-cb8f2d1391b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Aisle'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [1, 30]\n",
        "goal = [29, 2]\n",
        "map_range = 'A1:AF32'\n",
        "border = 32\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "puYdjJ_ygYVP",
        "outputId": "76d913bb-ef1c-425a-f72e-1e23d035f9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Double_door_16'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [1, 15]\n",
        "goal = [14, 1]\n",
        "map_range = 'A1:P16'\n",
        "border = 16\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5x0s0P8o1DqB",
        "outputId": "6e62ba93-bd06-49a3-906f-c1af5024f624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Canyon_16'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [2, 10]\n",
        "goal = [11, 1]\n",
        "map_range = 'A1:P16'\n",
        "border = 16\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "id": "cAPKDs5m6oGV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8d26b4a6-1520-48f8-9ee4-5c38af65c2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.script import default\n",
        "\n",
        "map_name = 'Aisle_16'\n",
        "path = '/content/gdrive/MyDrive/PPO_demo_v4/maps/' + map_name + '.xlsx'\n",
        "start = [1, 13]\n",
        "goal = [14, 1]\n",
        "map_range = 'A1:P16'\n",
        "border = 16\n",
        "agent = PPO(path, start, goal, map_range, border)\n",
        "device = agent.device\n",
        "\n",
        "agent.generate_map()\n",
        "agent.generate_dis_table()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7GYqpmKO1GFn",
        "outputId": "4b37bfa4-d59c-4bea-f118-3a4cb99bbc48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Wj5reESLZrYJ",
        "outputId": "cfb737b0-e6f7-41ef-a1d9-39026f9ecd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/PPO_demo_v4/maps/Double_door_24.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Here, there is commonly not necessary to conduct a long-time trainning that is possibly be interrupted. However, the code below can be run before training in case of sudden-offline problem. Please create a folder to make sure you can contain these backup files. ***"
      ],
      "metadata": {
        "id": "zutcch8fUqwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if delete existed records, please run this\n",
        "!rm /content/gdrive/MyDrive/PPO_demo_v4/configuration/avg_scores.txt\n",
        "!rm /content/gdrive/MyDrive/PPO_demo_v4/configuration/avg_steps.txt\n",
        "!rm /content/gdrive/MyDrive/PPO_demo_v4/configuration/episodes.txt\n",
        "!rm /content/gdrive/MyDrive/PPO_demo_v4/configuration/scores.txt\n",
        "!rm /content/gdrive/MyDrive/PPO_demo_v4/configuration/steps.txt"
      ],
      "metadata": {
        "id": "C0ACAeMM6op_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "afd75148-1a65-4ba5-b516-b72fbfb947b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if state a new train without existed records, please run this\n",
        "!touch /content/gdrive/MyDrive/PPO_demo_v4/configuration/avg_scores.txt\n",
        "!touch /content/gdrive/MyDrive/PPO_demo_v4/configuration/avg_steps.txt\n",
        "!touch /content/gdrive/MyDrive/PPO_demo_v4/configuration/episodes.txt\n",
        "!touch /content/gdrive/MyDrive/PPO_demo_v4/configuration/scores.txt\n",
        "!touch /content/gdrive/MyDrive/PPO_demo_v4/configuration/steps.txt"
      ],
      "metadata": {
        "id": "4gW14qm86spu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "acb96ff8-83b8-4912-9851-1be2d6e30603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = agent.load_episodes() # if the episodes.txt is newly created, please open it and input a '0' in the file.\n",
        "agent.load_records()\n",
        "\n",
        "steps = agent.total_step[-1] if len(agent.total_step) != 0 else 0\n",
        "total_avg = agent.total_avg[-1] if len(agent.total_avg) != 0 else 0\n"
      ],
      "metadata": {
        "id": "9h99yp_t4NWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(steps)\n",
        "print(total_avg)\n",
        "print(e)"
      ],
      "metadata": {
        "id": "XoTpm3lV4Ots"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# be careful! If a train process is interrupted (print(e) != 0), please remember to run this code if continue!\n",
        "agent.load_checkpoints()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "bNUnxPbwbMBP",
        "outputId": "314cb82c-7141-4ca6-e719-a9e42c832727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "iiKRYh5PWRmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 2000\n",
        "# dr = 0.5\n",
        "\n",
        "# agent.load_checkpoints()\n",
        "\n",
        "default_is_solved = False\n",
        "\n",
        "default_mode = 'Train'\n",
        "\n",
        "path_nodes = [agent.start_node.tolist()]\n",
        "searched_space = []\n",
        "\n",
        "agent.actor.train()\n",
        "agent.critic.train()\n",
        "\n",
        "\n",
        "for e in range(e, episodes):\n",
        "\n",
        "  agent.start_node = agent.vectorized_start(e)\n",
        "  agent.reset()\n",
        "  total_step = 0\n",
        "  score = 0.0\n",
        "  done_time = 0\n",
        "\n",
        "  index = e % agent.memory_len\n",
        "  agent.memory[index] = []\n",
        "\n",
        "\n",
        "  while list(agent.cur_node) != list(agent.target_node) and total_step < agent.step_thr:\n",
        "\n",
        "    obs = np.array(agent.double_hot(agent.cur_node) + agent.situation(agent.cur_node))\n",
        "    obs = torch.from_numpy(obs).type(torch.FloatTensor).unsqueeze(0).to(device)\n",
        "\n",
        "    # print(f\"state_obs_size: {obs.size()}\")\n",
        "\n",
        "    act, posb = agent.action_select(obs)\n",
        "\n",
        "    # print(possibilities)\n",
        "\n",
        "    # v_s_real = 0\n",
        "    # for i in range(0, 9):\n",
        "    #   if i == 0:\n",
        "    #     next_s = obs + torch.tensor([0, 0])\n",
        "    #   else:\n",
        "    #     next_s = obs + torch.tensor(agent.action_space[i-1])\n",
        "    #   if possibilities[i] == 0.0:\n",
        "    #     v_s_real += 0.0\n",
        "    #   else:\n",
        "    #     v_s_real += possibilities[i] * (agent.get_reward(i) + agent.gamma * agent.critic(next_s))\n",
        "\n",
        "    next_obs, reward, done, _ = agent.step(act)\n",
        "    n_o = np.array(agent.double_hot(next_obs[0])+agent.situation(next_obs[0]))\n",
        "    n_o = torch.from_numpy(n_o).type(torch.FloatTensor).unsqueeze(0).to(device)\n",
        "\n",
        "    # trans = Transition(obs, act, posb, entropy, reward, n_o, agent.x_max, agent.x_min, agent.y_max, agent.y_min)\n",
        "    trans = Transition(obs, act, posb, reward, n_o)\n",
        "    agent.save_trans(index, trans)\n",
        "    score += reward\n",
        "\n",
        "  # done processing 1\n",
        "\n",
        "    if done == True:\n",
        "      done_time += 1\n",
        "    else:\n",
        "      agent.pre_node = agent.cur_node\n",
        "      agent.cur_node = next_obs[0]\n",
        "\n",
        "    # done processing 2\n",
        "\n",
        "    # if done == True:\n",
        "    #   break\n",
        "\n",
        "    # agent.pre_node = agent.cur_node\n",
        "    # agent.cur_node = next_obs\n",
        "\n",
        "    total_step += 1\n",
        "\n",
        "    if agent.cur_node.tolist() not in searched_space:\n",
        "      searched_space.append(agent.cur_node.tolist())\n",
        "\n",
        "  # record the total scores and avg-scores of current episodes\n",
        "\n",
        "\n",
        "  avg = score / (total_step+1)\n",
        "  total_avg += avg\n",
        "  agent.total_avg.append(total_avg)\n",
        "\n",
        "  avg_score = total_avg / (e+1)\n",
        "  agent.avg.append(avg_score)\n",
        "\n",
        "  # record the total steps and avg-steps of current episodes\n",
        "  steps += total_step\n",
        "  agent.total_step.append(steps)\n",
        "\n",
        "  avg_step = steps / (e+1)\n",
        "  agent.avg_step.append(avg_step)\n",
        "\n",
        "  if (e+1) % agent.memory_len == 0:\n",
        "\n",
        "    # agent.train_process()\n",
        "\n",
        "    agent.critic_train()\n",
        "    agent.actor_train()\n",
        "\n",
        "    agent.save_episodes()\n",
        "    agent.save_records()\n",
        "\n",
        "  # # update learning rate\n",
        "  if e >= 500 and agent.a_lr > 0.0 and agent.a_lr - ((2e-4) / 1500) >= 0:\n",
        "    agent.entropy_coe -= 1.5e-5\n",
        "    agent.a_lr -= ((2e-4) / 1500)\n",
        "    # agent.c_lr -= (agent.c_lr / 10000)\n",
        "\n",
        "  # save checkpoints\n",
        "  agent.save_checkpoints()\n",
        "\n",
        "  # output records of each episodes\n",
        "  print(f\"episode {e+1}: start node: {agent.start_node.tolist()}, score: {round(score/(total_step+1), 2)}, avg score: {round(agent.avg[e], 2)}, step: {total_step}, avg step: {round(avg_step, 2)}, done_time: {done_time}\")"
      ],
      "metadata": {
        "id": "1_YnSNHD6vzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "afe8174a-0891-49f7-f61b-b07f180fdb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_scores = agent.avg\n",
        "avg_steps = agent.avg_step"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AGC19CmlN9Ug",
        "outputId": "541678ca-9687-4473-d629-fd51a0b21fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = list(i for i in range(0, len(avg_steps)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "S9WMq80AOACd",
        "outputId": "7808944f-6b35-431c-e0f8-3e8080025439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate statistic images**"
      ],
      "metadata": {
        "id": "4IUtwfxtXCoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_score = agent.avg\n",
        "l1 = plt.plot(episodes, avg_scores, 'r--')\n",
        "plt.title('Score')\n",
        "plt.xlabel('episodes')\n",
        "plt.ylabel('average score')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RQw7PpQjOB5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_step = agent.avg_step\n",
        "l2 = plt.plot(episodes, avg_steps, 'b--')\n",
        "plt.title('Steps')\n",
        "plt.xlabel('episodes')\n",
        "plt.ylabel('average steps')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l72T4j76OEfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate result images**"
      ],
      "metadata": {
        "id": "rcu4GtkYXQu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test process\n",
        "\n",
        "default_mode = 'Test'\n",
        "agent.load_checkpoints()\n",
        "agent.actor.eval()\n",
        "agent.critic.eval()\n",
        "path_nodes = [start]\n",
        "test_steps = 0\n",
        "agent.start_node = np.array(start)\n",
        "agent.target_node = np.array(goal)\n",
        "agent.cur_node = agent.start_node\n",
        "\n",
        "done_time = 0\n",
        "\n",
        "while list(agent.cur_node) != list(agent.target_node):\n",
        "  obs = np.array(agent.double_hot(agent.cur_node) + agent.situation(agent.cur_node))\n",
        "  obs = torch.from_numpy(obs).type(torch.FloatTensor).unsqueeze(0).to(device)\n",
        "  act, posb = agent.action_select(obs)\n",
        "\n",
        "  next_obs, reward, done, _ = agent.step(act)\n",
        "\n",
        "  if done == True:\n",
        "      done_time += 1\n",
        "  else:\n",
        "\n",
        "    agent.pre_node = agent.cur_node\n",
        "    agent.cur_node = next_obs[0]\n",
        "    if any(node==agent.cur_node.tolist() for node in path_nodes) == False:\n",
        "      path_nodes.append(agent.cur_node.tolist())\n",
        "\n",
        "  test_steps += 1\n",
        "print(f\"Total step: {test_steps}\")"
      ],
      "metadata": {
        "id": "w8-l_5HJOHMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate pic (beta)\n",
        "\n",
        "map_r = copy.deepcopy(agent.map)\n",
        "map_g = copy.deepcopy(map_r)\n",
        "map_b = copy.deepcopy(map_g)\n",
        "map = np.dstack((map_r, map_g, map_b)).astype(float)\n",
        "\n",
        "# generate searched nodes\n",
        "\n",
        "for node in searched_space:\n",
        "  x = node[0]\n",
        "  y = node[1]\n",
        "\n",
        "  map[x][y][0] = 0.0\n",
        "  map[x][y][1] = 1.0\n",
        "  map[x][y][2] = 0.0\n",
        "\n",
        "#\n",
        "\n",
        "delta_color = round(1.0 / len(path_nodes), 4)\n",
        "color_0 = 0.0\n",
        "color_2 = 1.0\n",
        "bas_dir_vector = np.array([0.0, 1.0])\n",
        "disp_vector = np.array(goal) - np.array(start)\n",
        "sum_angle = 0.0\n",
        "avg_angle = 0.0\n",
        "count = 0\n",
        "max_dev_times = 0\n",
        "\n",
        "for i in range(len(path_nodes)):\n",
        "\n",
        "  #  color it\n",
        "  node = path_nodes[i]\n",
        "\n",
        "  x = node[0]\n",
        "  y = node[1]\n",
        "\n",
        "  map[x][y][0] = color_0\n",
        "  map[x][y][1] = 0.0\n",
        "  map[x][y][2] = color_2\n",
        "\n",
        "  color_0 += delta_color\n",
        "  color_2 -= delta_color\n",
        "\n",
        "  if i == 0:\n",
        "    continue\n",
        "\n",
        "  count += 1\n",
        "  c_node = path_nodes[i]\n",
        "  p_node = path_nodes[i-1]\n",
        "\n",
        "  # calculate steeling angle and :\n",
        "  dir_vector = np.array(c_node) - np.array(p_node)\n",
        "  angle = abs(np.arccos(np.clip(np.dot(dir_vector, bas_dir_vector)/(np.linalg.norm(dir_vector)*np.linalg.norm(bas_dir_vector)), -1.0, 1.0)))\n",
        "  dis_angle = abs(np.arccos(np.clip(np.dot(dir_vector, disp_vector)/(np.linalg.norm(dir_vector)*np.linalg.norm(disp_vector)), -1.0, 1.0)))\n",
        "  angle = round(angle, 3)\n",
        "  dis_angle = round(dis_angle, 3)\n",
        "\n",
        "  sum_angle += angle\n",
        "  avg_angle = round(sum_angle / float(count), 2)\n",
        "\n",
        "  bas_dir_vector = dir_vector\n",
        "\n",
        "  if dis_angle > math.pi / 2.0:\n",
        "    max_dev_times += 1\n",
        "\n",
        "\n",
        "# s_x = start[0]\n",
        "# s_y = start[1]\n",
        "# g_x = goal[0]\n",
        "# g_y = goal[1]\n",
        "\n",
        "# map[s_x][s_y][0] = 1.0\n",
        "# map[s_x][s_y][1] = 0.0\n",
        "# map[s_x][s_y][2] = 1.0\n",
        "# map[g_x][g_y][0] = 1.0\n",
        "# map[g_x][g_y][1] = 1.0\n",
        "# map[g_x][g_y][2] = 0.0\n",
        "\n",
        "\n",
        "path_map = (map * 255.0).astype(int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_wvTZaWKLwT5",
        "outputId": "73cf6137-2cda-40ed-acea-bed4484e3596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 1, figsize=[12, 4])\n",
        "axes.imshow(path_map)\n",
        "axes.axis('off')"
      ],
      "metadata": {
        "id": "KUserUgXORWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}